{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt5mwiHf3uWSgty/XOsOAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sr606/LLM/blob/main/mermaid_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHUnP5EJ-WWI"
      },
      "outputs": [],
      "source": [
        "fastapi\n",
        "uvicorn\n",
        "python-dotenv\n",
        "openai>=1.0.0\n",
        "graphviz\n",
        "\n",
        "\n",
        "AZURE_OPENAI_API_KEY=your_key\n",
        "AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/\n",
        "AZURE_OPENAI_API_VERSION=2024-02-15-preview\n",
        "AZURE_OPENAI_DEPLOYMENT=your-deployment-name\n",
        "\n",
        "\n",
        "#parser\n",
        "def split_into_stages(text: str):\n",
        "    \"\"\"\n",
        "    Splits pseudocode into stage blocks.\n",
        "    Adjust marker if needed.\n",
        "    \"\"\"\n",
        "    blocks = text.split(\"// --- [\")\n",
        "    return [block.strip() for block in blocks if block.strip()]\n",
        "\n",
        "\n",
        "#llm_service\n",
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "class LLMService:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.client = AzureOpenAI(\n",
        "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
        "            api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
        "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "        )\n",
        "\n",
        "        self.deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
        "\n",
        "        self.system_prompt = \"\"\"\n",
        "You are an ETL Stage Analyzer.\n",
        "\n",
        "Extract:\n",
        "- stage_name\n",
        "- stage_type\n",
        "- short transformation summary (3-5 bullet points)\n",
        "\n",
        "Return valid JSON only in this format:\n",
        "\n",
        "{\n",
        "  \"stage_name\": \"...\",\n",
        "  \"stage_type\": \"...\",\n",
        "  \"summary\": [\n",
        "      \"bullet 1\",\n",
        "      \"bullet 2\",\n",
        "      \"bullet 3\"\n",
        "  ]\n",
        "}\n",
        "\n",
        "Do not include explanations.\n",
        "Do not include markdown.\n",
        "\"\"\"\n",
        "\n",
        "    def analyze_stage(self, stage_block: str):\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.deployment,\n",
        "            temperature=0.0,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "                {\"role\": \"user\", \"content\": stage_block}\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        try:\n",
        "            return json.loads(content)\n",
        "        except Exception:\n",
        "            return {\n",
        "                \"error\": \"Invalid JSON from LLM\",\n",
        "                \"raw_response\": content\n",
        "            }\n",
        "\n",
        "\n",
        "\n",
        "#agent\n",
        "import os\n",
        "import json\n",
        "from parser import split_into_stages\n",
        "from llm_service import LLMService\n",
        "\n",
        "INPUT_PATH = \"../data/input/pseudocode.txt\"\n",
        "OUTPUT_PATH = \"../data/output/metadata.json\"\n",
        "\n",
        "\n",
        "def run_agent():\n",
        "\n",
        "    if not os.path.exists(INPUT_PATH):\n",
        "        print(\"Input file not found.\")\n",
        "        return\n",
        "\n",
        "    with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        pseudocode = f.read()\n",
        "\n",
        "    stage_blocks = split_into_stages(pseudocode)\n",
        "\n",
        "    if not stage_blocks:\n",
        "        print(\"No stage blocks detected.\")\n",
        "        return\n",
        "\n",
        "    llm = LLMService()\n",
        "    results = []\n",
        "\n",
        "    for idx, block in enumerate(stage_blocks):\n",
        "        print(f\"Processing stage {idx+1}/{len(stage_blocks)}\")\n",
        "        result = llm.analyze_stage(block)\n",
        "        results.append(result)\n",
        "\n",
        "    os.makedirs(\"../data/output\", exist_ok=True)\n",
        "\n",
        "    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "    print(\"Extraction complete.\")\n",
        "    print(f\"Metadata saved at {OUTPUT_PATH}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_agent()\n",
        "\n",
        "\n",
        "\n",
        "#server\n",
        "from fastapi import FastAPI\n",
        "from agent import run_agent\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/generate-diagram\")\n",
        "def generate():\n",
        "    run_agent()\n",
        "    return {\"status\": \"success\", \"message\": \"Metadata generated\"}\n",
        "\n",
        "\n",
        "#client\n",
        "import requests\n",
        "\n",
        "response = requests.post(\"http://127.0.0.1:8000/generate-diagram\")\n",
        "\n",
        "print(response.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#graph_model\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, name, stage_type, summary):\n",
        "        self.name = name\n",
        "        self.stage_type = stage_type\n",
        "        self.summary = summary\n",
        "\n",
        "\n",
        "class Graph:\n",
        "    def __init__(self):\n",
        "        self.nodes = {}\n",
        "        self.edges = set()   # (source, target)\n",
        "\n",
        "    def add_node(self, node: Node):\n",
        "        self.nodes[node.name] = node\n",
        "\n",
        "    def add_edge(self, source, target):\n",
        "        if source != target:\n",
        "            self.edges.add((source, target))\n",
        "\n",
        "\n",
        "#graph_builder\n",
        "\n",
        "import re\n",
        "from graph_model import Graph, Node\n",
        "\n",
        "\n",
        "def build_graph(pseudocode_text, stage_metadata_list):\n",
        "    \"\"\"\n",
        "    Builds stage-to-stage graph deterministically.\n",
        "    \"\"\"\n",
        "\n",
        "    graph = Graph()\n",
        "\n",
        "    # -----------------------------\n",
        "    # Extract stage blocks again\n",
        "    # -----------------------------\n",
        "    pattern = r\"// --- \\[(.*?)\\] ---([\\s\\S]*?)(?=// --- \\[|$)\"\n",
        "    matches = re.findall(pattern, pseudocode_text)\n",
        "\n",
        "    dataset_producer = {}  # dataset_name -> stage_name\n",
        "    dataset_consumers = {}  # dataset_name -> [stage_names]\n",
        "\n",
        "    for header, body in matches:\n",
        "\n",
        "        parts = header.split(\":\")\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "\n",
        "        stage_name = parts[1].strip()\n",
        "\n",
        "        # Extract inputs\n",
        "        inputs = re.findall(r\"Input:\\s*←\\s*dataset_\\d+\\s*\\((.*?)\\)\", body)\n",
        "\n",
        "        for dataset in inputs:\n",
        "            dataset_consumers.setdefault(dataset, []).append(stage_name)\n",
        "\n",
        "        # Extract outputs\n",
        "        outputs = re.findall(r\"Output:\\s*→\\s*dataset_\\d+\\s*\\((.*?)\\)\", body)\n",
        "\n",
        "        for dataset in outputs:\n",
        "            dataset_producer[dataset] = stage_name\n",
        "\n",
        "    # -----------------------------\n",
        "    # Add Nodes from metadata\n",
        "    # -----------------------------\n",
        "    for stage_data in stage_metadata_list:\n",
        "        if \"error\" in stage_data:\n",
        "            continue\n",
        "\n",
        "        node = Node(\n",
        "            name=stage_data[\"stage_name\"],\n",
        "            stage_type=stage_data[\"stage_type\"],\n",
        "            summary=stage_data[\"summary\"]\n",
        "        )\n",
        "        graph.add_node(node)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Create stage-to-stage edges\n",
        "    # -----------------------------\n",
        "    for dataset, producer in dataset_producer.items():\n",
        "        consumers = dataset_consumers.get(dataset, [])\n",
        "\n",
        "        for consumer in consumers:\n",
        "            graph.add_edge(producer, consumer)\n",
        "\n",
        "    return graph\n",
        "\n",
        "\n",
        "\n",
        "#run_agent()\n",
        "\n",
        "from graph_builder import build_graph\n",
        "\n",
        "\n",
        "def run_agent():\n",
        "\n",
        "    with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        pseudocode = f.read()\n",
        "\n",
        "    stage_blocks = split_into_stages(pseudocode)\n",
        "\n",
        "    llm = LLMService()\n",
        "    metadata_results = []\n",
        "\n",
        "    for block in stage_blocks:\n",
        "        result = llm.analyze_stage(block)\n",
        "        metadata_results.append(result)\n",
        "\n",
        "    # Save metadata\n",
        "    os.makedirs(\"../data/output\", exist_ok=True)\n",
        "\n",
        "    with open(\"../data/output/metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metadata_results, f, indent=4)\n",
        "\n",
        "    # Build graph\n",
        "    graph = build_graph(pseudocode, metadata_results)\n",
        "\n",
        "    # Print graph info\n",
        "    print(\"Nodes:\")\n",
        "    for node in graph.nodes.values():\n",
        "        print(\"-\", node.name)\n",
        "\n",
        "    print(\"\\nEdges:\")\n",
        "    for edge in graph.edges:\n",
        "        print(\"-\", edge)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Extract link-file bindings\n",
        "\n",
        "link_file_matches = re.findall(r\"Link File \\((.*?)\\):\\s*(.*)\",body)\n",
        "\n",
        "stage_link_files = {}\n",
        "for link_name, file_name in link_file_matches:\n",
        "  stage_link_files[link_name.strip()] = file_name.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "PjtG95TfpfcF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}