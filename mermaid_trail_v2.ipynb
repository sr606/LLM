{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ1JZtbGgtsMfMMSxvMPqE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sr606/LLM/blob/main/mermaid_trail_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSXTp3V_nzlA",
        "outputId": "c8423810-c6a3-4433-f7fd-55681b0dd4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "added 1 package in 2s\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install -g mermaid-mcp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile diagram.mmd\n",
        "graph TD\n",
        "  A-->B\n",
        "  B-->C\n",
        "  C-->A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xERDglX4n2kX",
        "outputId": "f480aeaf-103e-423b-cb46-adecb4393ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing diagram.mmd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash -c \"export PATH=/usr/bin:$PATH; GLOBAL_NPM_BIN=$(/usr/bin/npm bin -g); export PATH=$GLOBAL_NPM_BIN:$PATH; mmdc -i diagram.mmd -o diagram.svg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUoswfrxn2my",
        "outputId": "8543e8a0-4b01-4375-c7f6-ce3f17cf9598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /usr/bin/npm: No such file or directory\n",
            "bash: line 1: mmdc: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "Parse a DataStage-like pseudo code text file and render a flowchart as PDF using GraphViz.\n",
        "\n",
        "Usage:\n",
        "    python pseudo_to_flowchart.py input.txt -o vor_job -f pdf --view\n",
        "\n",
        "Notes:\n",
        "- Groups nodes by StageType (clusters).\n",
        "- Connects stages by datasets: if Stage A outputs dataset_4 and Stage B inputs dataset_4, creates edge A -> B.\n",
        "- Edge labels show dataset and Link name (if found).\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "import argparse\n",
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "from graphviz import Digraph\n",
        "\n",
        "# ----------------------------\n",
        "# Data structures\n",
        "# ----------------------------\n",
        "\n",
        "@dataclass\n",
        "class DatasetRef:\n",
        "    dataset_id: str\n",
        "    dataset_name: Optional[str] = None\n",
        "    link_name: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class Stage:\n",
        "    stage_id: str\n",
        "    display_name: str\n",
        "    bracket_kind: Optional[str] = None      # e.g., CUSTOMSTAGE / HASHEDFILESTAGE (from header)\n",
        "    stage_type: Optional[str] = None        # e.g., OracleConnector / CTransformerStage (from body)\n",
        "    lines: List[str] = field(default_factory=list)\n",
        "    inputs: List[DatasetRef] = field(default_factory=list)\n",
        "    outputs: List[DatasetRef] = field(default_factory=list)\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "\n",
        "def sanitize_id(text: str) -> str:\n",
        "    \"\"\"Make a safe GraphViz node id.\"\"\"\n",
        "    text = re.sub(r\"[^A-Za-z0-9_]+\", \"_\", text.strip())\n",
        "    text = re.sub(r\"_{2,}\", \"_\", text)\n",
        "    return text.strip(\"_\") or \"node\"\n",
        "\n",
        "def esc(text: Optional[str]) -> str:\n",
        "    \"\"\"Escape < and > unless you intend to use HTML-like labels.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    return text.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
        "\n",
        "def parse_dataset_tokens(segment: str) -> List[DatasetRef]:\n",
        "    \"\"\"\n",
        "    Parse patterns like:\n",
        "      Input: ← dataset_4 (Tfm_LoadRecords) (Link: Load_HFVehicleoffRoad)\n",
        "      Output: → dataset_3 (HF_FACT_VOR_DATA)\n",
        "    Returns list of DatasetRef.\n",
        "    \"\"\"\n",
        "    # Split by commas or just parse all occurrences\n",
        "    refs: List[DatasetRef] = []\n",
        "\n",
        "    # Regex finds: dataset_# (Name) optional (Link: Xxx)\n",
        "    # dataset id\n",
        "    ds_pattern = re.compile(\n",
        "        r\"(dataset_\\d+)\\s*(?:\\(([^)]+)\\))?\\s*(?:\\(Link:\\s*([^)]+)\\))?\",\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    for m in ds_pattern.finditer(segment):\n",
        "        ds_id = m.group(1)\n",
        "        ds_name = m.group(2).strip() if m.group(2) else None\n",
        "        link = m.group(3).strip() if m.group(3) else None\n",
        "        refs.append(DatasetRef(dataset_id=ds_id, dataset_name=ds_name, link_name=link))\n",
        "\n",
        "    return refs\n",
        "\n",
        "# ----------------------------\n",
        "# Parser\n",
        "# ----------------------------\n",
        "\n",
        "def parse_pseudocode(path: str) -> List[Stage]:\n",
        "    \"\"\"\n",
        "    Parses a pseudo code file into a list of stages with inputs/outputs and types.\n",
        "    Recognizes:\n",
        "      // --- [CUSTOMSTAGE : Name] [Lines ...] ---\n",
        "      StageType: OracleConnector\n",
        "      Input: ← dataset_... (Name) (Link: ...)\n",
        "      Output: → dataset_... (Name)\n",
        "    \"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    stages: List[Stage] = []\n",
        "    current: Optional[Stage] = None\n",
        "    seen_ids: Dict[str, int] = defaultdict(int)\n",
        "\n",
        "    # Header pattern for stages\n",
        "    header_re = re.compile(\n",
        "        r\"^\\s*//\\s*---\\s*\\[\\s*([A-Z]+STAGE)\\s*:\\s*([^\\]]+?)\\s*\\]\\s*\\[.*?\\]\\s*---\\s*$\",\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    for raw in lines:\n",
        "        line = raw.rstrip(\"\\n\")\n",
        "\n",
        "        # New stage header?\n",
        "        h = header_re.match(line)\n",
        "        if h:\n",
        "            bracket_kind = h.group(1).strip()  # e.g., CUSTOMSTAGE, HASHEDFILESTAGE, TRANSFORMERSTAGE\n",
        "            display_name = h.group(2).strip()\n",
        "\n",
        "            # Create a unique stage_id\n",
        "            base_id = sanitize_id(display_name) or \"Stage\"\n",
        "            seen_ids[base_id] += 1\n",
        "            stage_id = base_id if seen_ids[base_id] == 1 else f\"{base_id}_{seen_ids[base_id]}\"\n",
        "\n",
        "            current = Stage(\n",
        "                stage_id=stage_id,\n",
        "                display_name=display_name,\n",
        "                bracket_kind=bracket_kind,\n",
        "            )\n",
        "            stages.append(current)\n",
        "            continue\n",
        "\n",
        "        if current is None:\n",
        "            # Outside any stage: skip\n",
        "            continue\n",
        "\n",
        "        current.lines.append(line)\n",
        "\n",
        "        # StageType\n",
        "        if line.strip().lower().startswith(\"stagetype:\"):\n",
        "            # e.g., StageType: OracleConnector\n",
        "            st = line.split(\":\", 1)[1].strip()\n",
        "            current.stage_type = st\n",
        "\n",
        "        # Input lines\n",
        "        if line.strip().lower().startswith(\"input:\"):\n",
        "            # capture the entire line (could contain multiple datasets)\n",
        "            in_refs = parse_dataset_tokens(line)\n",
        "            current.inputs.extend(in_refs)\n",
        "\n",
        "        # Output lines\n",
        "        if line.strip().lower().startswith(\"output:\"):\n",
        "            out_refs = parse_dataset_tokens(line)\n",
        "            current.outputs.extend(out_refs)\n",
        "\n",
        "    return stages\n",
        "\n",
        "# ----------------------------\n",
        "# Graph building\n",
        "# ----------------------------\n",
        "\n",
        "def build_graph(stages: List[Stage],\n",
        "                rankdir: str = \"LR\",\n",
        "                theme: str = \"default\") -> Digraph:\n",
        "    \"\"\"\n",
        "    Build a Digraph from stages, connecting producers and consumers through datasets.\n",
        "    \"\"\"\n",
        "    # cluster color themes by StageType (body)\n",
        "    cluster_palette = {\n",
        "        \"OracleConnector\":   (\"#5DADE2\", \"#EBF5FB\"),\n",
        "        \"CTransformerStage\": (\"#58D68D\", \"#E9F7EF\"),\n",
        "        \"CHashedFileStage\":  (\"#AF7AC5\", \"#F5EEF8\"),\n",
        "        \"CSeqFileStage\":     (\"#5499C7\", \"#EBF5FB\"),\n",
        "        # fallback\n",
        "        \"__default__\":       (\"#F4D03F\", \"#FEF9E7\"),\n",
        "    }\n",
        "\n",
        "    dot = Digraph(\n",
        "        name=\"ETL_Flow\",\n",
        "        graph_attr={\"rankdir\": rankdir, \"fontname\": \"Helvetica\"},\n",
        "        node_attr={\n",
        "            \"shape\": \"box\", \"style\": \"rounded,filled\", \"fontname\": \"Helvetica\",\n",
        "            \"fontsize\": \"10\", \"margin\": \"0.2,0.15\", \"fillcolor\": \"#FFFFFF\", \"color\": \"#2E4053\"\n",
        "        },\n",
        "        edge_attr={\"color\": \"#555555\", \"arrowsize\": \"0.8\"}\n",
        "    )\n",
        "\n",
        "    # Group stages by StageType (body)\n",
        "    by_type: Dict[str, List[Stage]] = defaultdict(list)\n",
        "    for s in stages:\n",
        "        key = s.stage_type or (s.bracket_kind or \"__default__\")\n",
        "        by_type[key].append(s)\n",
        "\n",
        "    # Keep a mapping from dataset -> producer stage(s)\n",
        "    producers: Dict[str, List[Tuple[Stage, DatasetRef]]] = defaultdict(list)\n",
        "    # Keep a mapping from dataset -> consumer stage(s)\n",
        "    consumers: Dict[str, List[Tuple[Stage, DatasetRef]]] = defaultdict(list)\n",
        "\n",
        "    # Render clusters and nodes\n",
        "    for s_type, s_list in by_type.items():\n",
        "        border, bg = cluster_palette.get(s_type, cluster_palette[\"__default__\"])\n",
        "        with dot.subgraph(name=f\"cluster_{sanitize_id(s_type)}\") as c:\n",
        "            c.attr(\n",
        "                label=esc(s_type),\n",
        "                style=\"rounded\",\n",
        "                color=border,\n",
        "                bgcolor=bg\n",
        "            )\n",
        "            for s in s_list:\n",
        "                label = f\"{s.display_name}\"\n",
        "                if s.stage_type:\n",
        "                    label += f\"\\n({s.stage_type})\"\n",
        "                elif s.bracket_kind:\n",
        "                    label += f\"\\n({s.bracket_kind})\"\n",
        "\n",
        "                # Tooltip summarizing IO\n",
        "                tooltip_parts = []\n",
        "                if s.inputs:\n",
        "                    tooltip_parts.append(\"Inputs: \" + \", \".join([r.dataset_id for r in s.inputs]))\n",
        "                if s.outputs:\n",
        "                    tooltip_parts.append(\"Outputs: \" + \", \".join([r.dataset_id for r in s.outputs]))\n",
        "                tooltip = \"; \".join(tooltip_parts) if tooltip_parts else None\n",
        "\n",
        "                c.node(s.stage_id, label=esc(label), tooltip=esc(tooltip) if tooltip else None)\n",
        "\n",
        "                # Track producers & consumers by dataset id\n",
        "                for ref in s.outputs:\n",
        "                    producers[ref.dataset_id].append((s, ref))\n",
        "                for ref in s.inputs:\n",
        "                    consumers[ref.dataset_id].append((s, ref))\n",
        "\n",
        "    # Create edges producer -> consumer for shared datasets\n",
        "    seen_edges = set()\n",
        "    for ds_id, prod_list in producers.items():\n",
        "        cons_list = consumers.get(ds_id, [])\n",
        "        for (p_stage, p_ref) in prod_list:\n",
        "            for (c_stage, c_ref) in cons_list:\n",
        "                if p_stage.stage_id == c_stage.stage_id:\n",
        "                    continue\n",
        "                edge_key = (p_stage.stage_id, c_stage.stage_id, ds_id)\n",
        "                if edge_key in seen_edges:\n",
        "                    continue\n",
        "                seen_edges.add(edge_key)\n",
        "\n",
        "                # Build label: dataset + (Link names if any)\n",
        "                labels = [ds_id]\n",
        "                # Prefer consumer link if present, else producer link\n",
        "                link_name = c_ref.link_name or p_ref.link_name\n",
        "                if link_name:\n",
        "                    labels.append(f\"Link: {link_name}\")\n",
        "                # If dataset has a display alias, include once\n",
        "                alias = c_ref.dataset_name or p_ref.dataset_name\n",
        "                if alias and alias != ds_id:\n",
        "                    labels.append(alias)\n",
        "\n",
        "                edge_label = \" | \".join(labels)\n",
        "                dot.edge(p_stage.stage_id, c_stage.stage_id, label=esc(edge_label))\n",
        "\n",
        "    return dot\n",
        "\n",
        "# ----------------------------\n",
        "# CLI\n",
        "# ----------------------------\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"Convert pseudo code text file to flowchart (GraphViz).\")\n",
        "    ap.add_argument(\"input\", help=\"Path to pseudo code text file\")\n",
        "    ap.add_argument(\"-o\", \"--output\", default=\"flowchart\", help=\"Output filename without extension (default: flowchart)\")\n",
        "    ap.add_argument(\"-d\", \"--directory\", default=None, help=\"Output directory\")\n",
        "    ap.add_argument(\"-f\", \"--format\", default=\"pdf\", choices=[\"pdf\", \"png\", \"svg\"], help=\"Output format (default: pdf)\")\n",
        "    ap.add_argument(\"--rankdir\", default=\"LR\", choices=[\"LR\", \"TB\", \"BT\", \"RL\"], help=\"Graph layout direction (default: LR)\")\n",
        "    ap.add_argument(\"--view\", action=\"store_true\", help=\"Open the rendered file after creation\")\n",
        "    ap.add_argument(\"--cleanup\", action=\"store_true\", help=\"Remove intermediate files after render\")\n",
        "    args = ap.parse_args(['/content/LS_Sample_job1 1 2_detailed_pseudocode.txt', '--output', 'flowchart', '--format', 'pdf', '--cleanup'])\n",
        "\n",
        "    if not os.path.exists(args.input):\n",
        "        raise FileNotFoundError(f\"Input file not found: {args.input}\")\n",
        "\n",
        "    stages = parse_pseudocode(args.input)\n",
        "\n",
        "    if not stages:\n",
        "        raise RuntimeError(\"No stages detected. Ensure the pseudo code contains stage headers like:\\n\"\n",
        "                           \"// --- [CUSTOMSTAGE : Name] [Lines ...] ---\")\n",
        "\n",
        "    dot = build_graph(stages, rankdir=args.rankdir)\n",
        "    path = dot.render(filename=args.output, directory=args.directory, format=args.format, view=args.view, cleanup=args.cleanup)\n",
        "    print(f\"Rendered: {path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "iQIgCb2kn2pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729d4294-24b8-47da-f3ac-05a1a86dfbc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendered: flowchart.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from graphviz import Digraph\n",
        "\n",
        "def parse_pseudocode(text):\n",
        "    \"\"\"\n",
        "    Extracts stages, inputs, outputs from pseudocode blocks.\n",
        "    \"\"\"\n",
        "    stages = []\n",
        "    current_stage = None\n",
        "\n",
        "    lines = text.splitlines()\n",
        "\n",
        "    stage_header_pattern = re.compile(r'^\\s*// --- \\[(.*?)\\]\\s*')\n",
        "    input_pattern = re.compile(r'Input:\\s*←\\s*(.*?)\\s*\\(')\n",
        "    output_pattern = re.compile(r'Output:\\s*→\\s*(.*?)\\s*\\(')\n",
        "\n",
        "    for line in lines:\n",
        "        header_match = stage_header_pattern.search(line)\n",
        "        if header_match:\n",
        "            # Start new stage\n",
        "            if current_stage:\n",
        "                stages.append(current_stage)\n",
        "            current_stage = {\n",
        "                \"name\": header_match.group(1),\n",
        "                \"inputs\": [],\n",
        "                \"outputs\": []\n",
        "            }\n",
        "\n",
        "        if current_stage:\n",
        "            input_match = input_pattern.search(line)\n",
        "            if input_match:\n",
        "                current_stage[\"inputs\"].append(input_match.group(1).strip())\n",
        "\n",
        "            output_match = output_pattern.search(line)\n",
        "            if output_match:\n",
        "                current_stage[\"outputs\"].append(output_match.group(1).strip())\n",
        "\n",
        "    # Add last stage\n",
        "    if current_stage:\n",
        "        stages.append(current_stage)\n",
        "\n",
        "    return stages\n",
        "\n",
        "\n",
        "def build_graph(stages):\n",
        "    \"\"\"\n",
        "    Builds a Graphviz Diagram from parsed stages.\n",
        "    \"\"\"\n",
        "    g = Digraph(\"JobFlow\", format=\"png\")\n",
        "    g.attr(rankdir=\"LR\", fontsize=\"10\")\n",
        "\n",
        "    # Add stage nodes\n",
        "    for stg in stages:\n",
        "        g.node(stg[\"name\"], stg[\"name\"], shape=\"box\", style=\"rounded,filled\", color=\"lightblue\")\n",
        "\n",
        "    # Create edges from inputs to stages and stages to outputs\n",
        "    for stg in stages:\n",
        "        for inp in stg[\"inputs\"]:\n",
        "            g.node(inp, inp, shape=\"ellipse\", color=\"gray\")\n",
        "            g.edge(inp, stg[\"name\"])\n",
        "\n",
        "        for out in stg[\"outputs\"]:\n",
        "            g.node(out, out, shape=\"ellipse\", color=\"gray\")\n",
        "            g.edge(stg[\"name\"], out)\n",
        "\n",
        "    return g\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# USE IT\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    with open(\"LS_Sample_job1 1 2_detailed_pseudocode.txt\", \"r\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    stages = parse_pseudocode(content)\n",
        "    graph = build_graph(stages)\n",
        "    graph.render(\"Job_Stage_Diagram\", cleanup=True)\n",
        "\n",
        "    print(\"Diagram generated: Job_Stage_Diagram.png\")"
      ],
      "metadata": {
        "id": "uPZbtgtRn2sM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ccaf326-3e6b-4e4c-b00a-cae52b211a3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: node HASHEDFILESTAGE , port  HSH_MIDTERM_HIST unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Employee_Changes_reporting unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_MIDTERM_HIST unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_BARCLAYS_EMPLOYEE_ACTION unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_STG_F_BARCLAYS_MIDTERM_HIST unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  Rule_Lkps unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  EMP_ACT_CHG_REP_FLAG_HSH unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_TEMP_STGVAR_EMPLOYEE_CODE_CHNG unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  Xfm_UpdStgbarclayMidterm unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_BARCLAYS_EMPLOYEE_ACTION unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  tfmLookupSubmittedCount unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_STG_F_BARCLAYS_MIDTERM_HIST unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  tfmLookupSubmittedCount unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  tfmLookupSubmittedCount unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  Xfm_UpdStgbarclayMidterm unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Employee_Changes_reporting unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Reporting_flag unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_RuleLkps unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_STG_F_BARCLAYS_MIDTERM unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_STG_EMPLOYEE_CHANGES_REPORTING unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Reporting_flag unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Reporting_flag unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Reporting_flag unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  EMP_ACT_CHG_REP_FLAG_HSH unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_TEMP_STGVAR_EMPLOYEE_CODE_CHNG unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  Rule_Lkps unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  Rule_Lkps unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_RuleLkps unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  OraD_BARCLAYS_EMPLOYEE_ACTION unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  ora_STG_F_BARCLAYS_MIDTERM_HIST unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_STG_EMPLOYEE_CHANGES_REPORTING unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_EMPLOYEE_ACTION_CHANGES_RULES unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_STG_F_BARCLAYS_MIDTERM unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  ora_NOLSData unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  tfmLookupSubmittedCount unrecognized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagram generated: Job_Stage_Diagram.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VEKzWOIbn2u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QiqBR4Bn2xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ps0QFYen2zu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}