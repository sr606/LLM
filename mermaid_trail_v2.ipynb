{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sr606/LLM/blob/main/mermaid_trail_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSXTp3V_nzlA",
        "outputId": "c8423810-c6a3-4433-f7fd-55681b0dd4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "added 1 package in 2s\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install -g mermaid-mcp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile diagram.mmd\n",
        "graph TD\n",
        "  A-->B\n",
        "  B-->C\n",
        "  C-->A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xERDglX4n2kX",
        "outputId": "f480aeaf-103e-423b-cb46-adecb4393ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing diagram.mmd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash -c \"export PATH=/usr/bin:$PATH; GLOBAL_NPM_BIN=$(/usr/bin/npm bin -g); export PATH=$GLOBAL_NPM_BIN:$PATH; mmdc -i diagram.mmd -o diagram.svg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUoswfrxn2my",
        "outputId": "8543e8a0-4b01-4375-c7f6-ce3f17cf9598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /usr/bin/npm: No such file or directory\n",
            "bash: line 1: mmdc: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "Parse a DataStage-like pseudo code text file and render a flowchart as PDF using GraphViz.\n",
        "\n",
        "Usage:\n",
        "    python pseudo_to_flowchart.py input.txt -o vor_job -f pdf --view\n",
        "\n",
        "Notes:\n",
        "- Groups nodes by StageType (clusters).\n",
        "- Connects stages by datasets: if Stage A outputs dataset_4 and Stage B inputs dataset_4, creates edge A -> B.\n",
        "- Edge labels show dataset and Link name (if found).\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "import argparse\n",
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "from graphviz import Digraph\n",
        "\n",
        "# ----------------------------\n",
        "# Data structures\n",
        "# ----------------------------\n",
        "\n",
        "@dataclass\n",
        "class DatasetRef:\n",
        "    dataset_id: str\n",
        "    dataset_name: Optional[str] = None\n",
        "    link_name: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class Stage:\n",
        "    stage_id: str\n",
        "    display_name: str\n",
        "    bracket_kind: Optional[str] = None      # e.g., CUSTOMSTAGE / HASHEDFILESTAGE (from header)\n",
        "    stage_type: Optional[str] = None        # e.g., OracleConnector / CTransformerStage (from body)\n",
        "    lines: List[str] = field(default_factory=list)\n",
        "    inputs: List[DatasetRef] = field(default_factory=list)\n",
        "    outputs: List[DatasetRef] = field(default_factory=list)\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "\n",
        "def sanitize_id(text: str) -> str:\n",
        "    \"\"\"Make a safe GraphViz node id.\"\"\"\n",
        "    text = re.sub(r\"[^A-Za-z0-9_]+\", \"_\", text.strip())\n",
        "    text = re.sub(r\"_{2,}\", \"_\", text)\n",
        "    return text.strip(\"_\") or \"node\"\n",
        "\n",
        "def esc(text: Optional[str]) -> str:\n",
        "    \"\"\"Escape < and > unless you intend to use HTML-like labels.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    return text.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
        "\n",
        "def parse_dataset_tokens(segment: str) -> List[DatasetRef]:\n",
        "    \"\"\"\n",
        "    Parse patterns like:\n",
        "      Input: ← dataset_4 (Tfm_LoadRecords) (Link: Load_HFVehicleoffRoad)\n",
        "      Output: → dataset_3 (HF_FACT_VOR_DATA)\n",
        "    Returns list of DatasetRef.\n",
        "    \"\"\"\n",
        "    # Split by commas or just parse all occurrences\n",
        "    refs: List[DatasetRef] = []\n",
        "\n",
        "    # Regex finds: dataset_# (Name) optional (Link: Xxx)\n",
        "    # dataset id\n",
        "    ds_pattern = re.compile(\n",
        "        r\"(dataset_\\d+)\\s*(?:\\(([^)]+)\\))?\\s*(?:\\(Link:\\s*([^)]+)\\))?\",\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    for m in ds_pattern.finditer(segment):\n",
        "        ds_id = m.group(1)\n",
        "        ds_name = m.group(2).strip() if m.group(2) else None\n",
        "        link = m.group(3).strip() if m.group(3) else None\n",
        "        refs.append(DatasetRef(dataset_id=ds_id, dataset_name=ds_name, link_name=link))\n",
        "\n",
        "    return refs\n",
        "\n",
        "# ----------------------------\n",
        "# Parser\n",
        "# ----------------------------\n",
        "\n",
        "def parse_pseudocode(path: str) -> List[Stage]:\n",
        "    \"\"\"\n",
        "    Parses a pseudo code file into a list of stages with inputs/outputs and types.\n",
        "    Recognizes:\n",
        "      // --- [CUSTOMSTAGE : Name] [Lines ...] ---\n",
        "      StageType: OracleConnector\n",
        "      Input: ← dataset_... (Name) (Link: ...)\n",
        "      Output: → dataset_... (Name)\n",
        "    \"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    stages: List[Stage] = []\n",
        "    current: Optional[Stage] = None\n",
        "    seen_ids: Dict[str, int] = defaultdict(int)\n",
        "\n",
        "    # Header pattern for stages\n",
        "    header_re = re.compile(\n",
        "        r\"^\\s*//\\s*---\\s*\\[\\s*([A-Z]+STAGE)\\s*:\\s*([^\\]]+?)\\s*\\]\\s*\\[.*?\\]\\s*---\\s*$\",\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    for raw in lines:\n",
        "        line = raw.rstrip(\"\\n\")\n",
        "\n",
        "        # New stage header?\n",
        "        h = header_re.match(line)\n",
        "        if h:\n",
        "            bracket_kind = h.group(1).strip()  # e.g., CUSTOMSTAGE, HASHEDFILESTAGE, TRANSFORMERSTAGE\n",
        "            display_name = h.group(2).strip()\n",
        "\n",
        "            # Create a unique stage_id\n",
        "            base_id = sanitize_id(display_name) or \"Stage\"\n",
        "            seen_ids[base_id] += 1\n",
        "            stage_id = base_id if seen_ids[base_id] == 1 else f\"{base_id}_{seen_ids[base_id]}\"\n",
        "\n",
        "            current = Stage(\n",
        "                stage_id=stage_id,\n",
        "                display_name=display_name,\n",
        "                bracket_kind=bracket_kind,\n",
        "            )\n",
        "            stages.append(current)\n",
        "            continue\n",
        "\n",
        "        if current is None:\n",
        "            # Outside any stage: skip\n",
        "            continue\n",
        "\n",
        "        current.lines.append(line)\n",
        "\n",
        "        # StageType\n",
        "        if line.strip().lower().startswith(\"stagetype:\"):\n",
        "            # e.g., StageType: OracleConnector\n",
        "            st = line.split(\":\", 1)[1].strip()\n",
        "            current.stage_type = st\n",
        "\n",
        "        # Input lines\n",
        "        if line.strip().lower().startswith(\"input:\"):\n",
        "            # capture the entire line (could contain multiple datasets)\n",
        "            in_refs = parse_dataset_tokens(line)\n",
        "            current.inputs.extend(in_refs)\n",
        "\n",
        "        # Output lines\n",
        "        if line.strip().lower().startswith(\"output:\"):\n",
        "            out_refs = parse_dataset_tokens(line)\n",
        "            current.outputs.extend(out_refs)\n",
        "\n",
        "    return stages\n",
        "\n",
        "# ----------------------------\n",
        "# Graph building\n",
        "# ----------------------------\n",
        "\n",
        "def build_graph(stages: List[Stage],\n",
        "                rankdir: str = \"LR\",\n",
        "                theme: str = \"default\") -> Digraph:\n",
        "    \"\"\"\n",
        "    Build a Digraph from stages, connecting producers and consumers through datasets.\n",
        "    \"\"\"\n",
        "    # cluster color themes by StageType (body)\n",
        "    cluster_palette = {\n",
        "        \"OracleConnector\":   (\"#5DADE2\", \"#EBF5FB\"),\n",
        "        \"CTransformerStage\": (\"#58D68D\", \"#E9F7EF\"),\n",
        "        \"CHashedFileStage\":  (\"#AF7AC5\", \"#F5EEF8\"),\n",
        "        \"CSeqFileStage\":     (\"#5499C7\", \"#EBF5FB\"),\n",
        "        # fallback\n",
        "        \"__default__\":       (\"#F4D03F\", \"#FEF9E7\"),\n",
        "    }\n",
        "\n",
        "    dot = Digraph(\n",
        "        name=\"ETL_Flow\",\n",
        "        graph_attr={\"rankdir\": rankdir, \"fontname\": \"Helvetica\"},\n",
        "        node_attr={\n",
        "            \"shape\": \"box\", \"style\": \"rounded,filled\", \"fontname\": \"Helvetica\",\n",
        "            \"fontsize\": \"10\", \"margin\": \"0.2,0.15\", \"fillcolor\": \"#FFFFFF\", \"color\": \"#2E4053\"\n",
        "        },\n",
        "        edge_attr={\"color\": \"#555555\", \"arrowsize\": \"0.8\"}\n",
        "    )\n",
        "\n",
        "    # Group stages by StageType (body)\n",
        "    by_type: Dict[str, List[Stage]] = defaultdict(list)\n",
        "    for s in stages:\n",
        "        key = s.stage_type or (s.bracket_kind or \"__default__\")\n",
        "        by_type[key].append(s)\n",
        "\n",
        "    # Keep a mapping from dataset -> producer stage(s)\n",
        "    producers: Dict[str, List[Tuple[Stage, DatasetRef]]] = defaultdict(list)\n",
        "    # Keep a mapping from dataset -> consumer stage(s)\n",
        "    consumers: Dict[str, List[Tuple[Stage, DatasetRef]]] = defaultdict(list)\n",
        "\n",
        "    # Render clusters and nodes\n",
        "    for s_type, s_list in by_type.items():\n",
        "        border, bg = cluster_palette.get(s_type, cluster_palette[\"__default__\"])\n",
        "        with dot.subgraph(name=f\"cluster_{sanitize_id(s_type)}\") as c:\n",
        "            c.attr(\n",
        "                label=esc(s_type),\n",
        "                style=\"rounded\",\n",
        "                color=border,\n",
        "                bgcolor=bg\n",
        "            )\n",
        "            for s in s_list:\n",
        "                label = f\"{s.display_name}\"\n",
        "                if s.stage_type:\n",
        "                    label += f\"\\n({s.stage_type})\"\n",
        "                elif s.bracket_kind:\n",
        "                    label += f\"\\n({s.bracket_kind})\"\n",
        "\n",
        "                # Tooltip summarizing IO\n",
        "                tooltip_parts = []\n",
        "                if s.inputs:\n",
        "                    tooltip_parts.append(\"Inputs: \" + \", \".join([r.dataset_id for r in s.inputs]))\n",
        "                if s.outputs:\n",
        "                    tooltip_parts.append(\"Outputs: \" + \", \".join([r.dataset_id for r in s.outputs]))\n",
        "                tooltip = \"; \".join(tooltip_parts) if tooltip_parts else None\n",
        "\n",
        "                c.node(s.stage_id, label=esc(label), tooltip=esc(tooltip) if tooltip else None)\n",
        "\n",
        "                # Track producers & consumers by dataset id\n",
        "                for ref in s.outputs:\n",
        "                    producers[ref.dataset_id].append((s, ref))\n",
        "                for ref in s.inputs:\n",
        "                    consumers[ref.dataset_id].append((s, ref))\n",
        "\n",
        "    # Create edges producer -> consumer for shared datasets\n",
        "    seen_edges = set()\n",
        "    for ds_id, prod_list in producers.items():\n",
        "        cons_list = consumers.get(ds_id, [])\n",
        "        for (p_stage, p_ref) in prod_list:\n",
        "            for (c_stage, c_ref) in cons_list:\n",
        "                if p_stage.stage_id == c_stage.stage_id:\n",
        "                    continue\n",
        "                edge_key = (p_stage.stage_id, c_stage.stage_id, ds_id)\n",
        "                if edge_key in seen_edges:\n",
        "                    continue\n",
        "                seen_edges.add(edge_key)\n",
        "\n",
        "                # Build label: dataset + (Link names if any)\n",
        "                labels = [ds_id]\n",
        "                # Prefer consumer link if present, else producer link\n",
        "                link_name = c_ref.link_name or p_ref.link_name\n",
        "                if link_name:\n",
        "                    labels.append(f\"Link: {link_name}\")\n",
        "                # If dataset has a display alias, include once\n",
        "                alias = c_ref.dataset_name or p_ref.dataset_name\n",
        "                if alias and alias != ds_id:\n",
        "                    labels.append(alias)\n",
        "\n",
        "                edge_label = \" | \".join(labels)\n",
        "                dot.edge(p_stage.stage_id, c_stage.stage_id, label=esc(edge_label))\n",
        "\n",
        "    return dot\n",
        "\n",
        "# ----------------------------\n",
        "# CLI\n",
        "# ----------------------------\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"Convert pseudo code text file to flowchart (GraphViz).\")\n",
        "    ap.add_argument(\"input\", help=\"Path to pseudo code text file\")\n",
        "    ap.add_argument(\"-o\", \"--output\", default=\"flowchart\", help=\"Output filename without extension (default: flowchart)\")\n",
        "    ap.add_argument(\"-d\", \"--directory\", default=None, help=\"Output directory\")\n",
        "    ap.add_argument(\"-f\", \"--format\", default=\"pdf\", choices=[\"pdf\", \"png\", \"svg\"], help=\"Output format (default: pdf)\")\n",
        "    ap.add_argument(\"--rankdir\", default=\"LR\", choices=[\"LR\", \"TB\", \"BT\", \"RL\"], help=\"Graph layout direction (default: LR)\")\n",
        "    ap.add_argument(\"--view\", action=\"store_true\", help=\"Open the rendered file after creation\")\n",
        "    ap.add_argument(\"--cleanup\", action=\"store_true\", help=\"Remove intermediate files after render\")\n",
        "    args = ap.parse_args(['/content/LS_Sample_job1 1 2_detailed_pseudocode.txt', '--output', 'flowchart', '--format', 'pdf', '--cleanup'])\n",
        "\n",
        "    if not os.path.exists(args.input):\n",
        "        raise FileNotFoundError(f\"Input file not found: {args.input}\")\n",
        "\n",
        "    stages = parse_pseudocode(args.input)\n",
        "\n",
        "    if not stages:\n",
        "        raise RuntimeError(\"No stages detected. Ensure the pseudo code contains stage headers like:\\n\"\n",
        "                           \"// --- [CUSTOMSTAGE : Name] [Lines ...] ---\")\n",
        "\n",
        "    dot = build_graph(stages, rankdir=args.rankdir)\n",
        "    path = dot.render(filename=args.output, directory=args.directory, format=args.format, view=args.view, cleanup=args.cleanup)\n",
        "    print(f\"Rendered: {path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "iQIgCb2kn2pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729d4294-24b8-47da-f3ac-05a1a86dfbc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendered: flowchart.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from graphviz import Digraph\n",
        "\n",
        "def parse_pseudocode(text):\n",
        "    \"\"\"\n",
        "    Extracts stages, inputs, outputs from pseudocode blocks.\n",
        "    \"\"\"\n",
        "    stages = []\n",
        "    current_stage = None\n",
        "\n",
        "    lines = text.splitlines()\n",
        "\n",
        "    stage_header_pattern = re.compile(r'^\\s*// --- \\[(.*?)\\]\\s*')\n",
        "    input_pattern = re.compile(r'Input:\\s*←\\s*(.*?)\\s*\\(')\n",
        "    output_pattern = re.compile(r'Output:\\s*→\\s*(.*?)\\s*\\(')\n",
        "\n",
        "    for line in lines:\n",
        "        header_match = stage_header_pattern.search(line)\n",
        "        if header_match:\n",
        "            # Start new stage\n",
        "            if current_stage:\n",
        "                stages.append(current_stage)\n",
        "            current_stage = {\n",
        "                \"name\": header_match.group(1),\n",
        "                \"inputs\": [],\n",
        "                \"outputs\": []\n",
        "            }\n",
        "\n",
        "        if current_stage:\n",
        "            input_match = input_pattern.search(line)\n",
        "            if input_match:\n",
        "                current_stage[\"inputs\"].append(input_match.group(1).strip())\n",
        "\n",
        "            output_match = output_pattern.search(line)\n",
        "            if output_match:\n",
        "                current_stage[\"outputs\"].append(output_match.group(1).strip())\n",
        "\n",
        "    # Add last stage\n",
        "    if current_stage:\n",
        "        stages.append(current_stage)\n",
        "\n",
        "    return stages\n",
        "\n",
        "\n",
        "def build_graph(stages):\n",
        "    \"\"\"\n",
        "    Builds a Graphviz Diagram from parsed stages.\n",
        "    \"\"\"\n",
        "    g = Digraph(\"JobFlow\", format=\"png\")\n",
        "    g.attr(rankdir=\"LR\", fontsize=\"10\")\n",
        "\n",
        "    # Add stage nodes\n",
        "    for stg in stages:\n",
        "        g.node(stg[\"name\"], stg[\"name\"], shape=\"box\", style=\"rounded,filled\", color=\"lightblue\")\n",
        "\n",
        "    # Create edges from inputs to stages and stages to outputs\n",
        "    for stg in stages:\n",
        "        for inp in stg[\"inputs\"]:\n",
        "            g.node(inp, inp, shape=\"ellipse\", color=\"gray\")\n",
        "            g.edge(inp, stg[\"name\"])\n",
        "\n",
        "        for out in stg[\"outputs\"]:\n",
        "            g.node(out, out, shape=\"ellipse\", color=\"gray\")\n",
        "            g.edge(stg[\"name\"], out)\n",
        "\n",
        "    return g\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# USE IT\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    with open(\"LS_Sample_job1 1 2_detailed_pseudocode.txt\", \"r\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    stages = parse_pseudocode(content)\n",
        "    graph = build_graph(stages)\n",
        "    graph.render(\"Job_Stage_Diagram\", cleanup=True)\n",
        "\n",
        "    print(\"Diagram generated: Job_Stage_Diagram.png\")"
      ],
      "metadata": {
        "id": "uPZbtgtRn2sM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ccaf326-3e6b-4e4c-b00a-cae52b211a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: node HASHEDFILESTAGE , port  HSH_MIDTERM_HIST unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Employee_Changes_reporting unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_MIDTERM_HIST unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_BARCLAYS_EMPLOYEE_ACTION unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_STG_F_BARCLAYS_MIDTERM_HIST unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  Rule_Lkps unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  EMP_ACT_CHG_REP_FLAG_HSH unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_TEMP_STGVAR_EMPLOYEE_CODE_CHNG unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  Xfm_UpdStgbarclayMidterm unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_BARCLAYS_EMPLOYEE_ACTION unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  tfmLookupSubmittedCount unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_STG_F_BARCLAYS_MIDTERM_HIST unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  tfmLookupSubmittedCount unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  tfmLookupSubmittedCount unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  Xfm_UpdStgbarclayMidterm unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Employee_Changes_reporting unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Reporting_flag unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_RuleLkps unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_STG_F_BARCLAYS_MIDTERM unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_STG_EMPLOYEE_CHANGES_REPORTING unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Reporting_flag unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Reporting_flag unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_Reporting_flag unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  EMP_ACT_CHG_REP_FLAG_HSH unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  HSH_TEMP_STGVAR_EMPLOYEE_CODE_CHNG unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  Rule_Lkps unrecognized\n",
            "Warning: node HASHEDFILESTAGE , port  Rule_Lkps unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  xfm_RuleLkps unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  OraD_BARCLAYS_EMPLOYEE_ACTION unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  ora_STG_F_BARCLAYS_MIDTERM_HIST unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_STG_EMPLOYEE_CHANGES_REPORTING unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_EMPLOYEE_ACTION_CHANGES_RULES unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  Ora_STG_F_BARCLAYS_MIDTERM unrecognized\n",
            "Warning: node CUSTOMSTAGE , port  ora_NOLSData unrecognized\n",
            "Warning: node TRANSFORMERSTAGE , port  tfmLookupSubmittedCount unrecognized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagram generated: Job_Stage_Diagram.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell previously contained DOT language code, which has been moved to cell 4QiqBR4Bn2xf for proper rendering."
      ],
      "metadata": {
        "id": "VEKzWOIbn2u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Source\n",
        "\n",
        "dot_code = \"\"\"\n",
        "digraph LS_Sample_job1_Architecture {\n",
        "\n",
        "    rankdir=LR;\n",
        "    splines=ortho;\n",
        "    nodesep=0.6;\n",
        "    ranksep=0.8;\n",
        "    fontname=\"Helvetica\";\n",
        "\n",
        "    node [\n",
        "        shape=box,\n",
        "        style=\"rounded,filled\",\n",
        "        fillcolor=\"#F4F6F7\",\n",
        "        color=\"#2C3E50\",\n",
        "        fontname=\"Helvetica\",\n",
        "        fontsize=10,\n",
        "        width=3,\n",
        "        height=0.8\n",
        "    ];\n",
        "\n",
        "    edge [\n",
        "        color=\"#34495E\",\n",
        "        arrowsize=0.8\n",
        "    ];\n",
        "\n",
        "    // =====================================================\n",
        "    // 1. SOURCE LAYER\n",
        "    // =====================================================\n",
        "    subgraph cluster_source {\n",
        "        label=\"SOURCE LAYER (Oracle)\";\n",
        "        color=\"#D5DBDB\";\n",
        "\n",
        "        src_midterm_hist [label=\"STG_F_BARCLAYS_MIDTERM_HIST\"];\n",
        "        src_prev_hist    [label=\"F_BARCLAYS_MIDTERM_HIST\"];\n",
        "        src_grade_dim    [label=\"CUST_DRIVER_GRADE_DIM\"];\n",
        "        src_upload       [label=\"DRIVER_UPLOAD_EMAIL_DETAILS\"];\n",
        "        src_action_dim   [label=\"D_BARCLAYS_EMPLOYEE_ACTION\"];\n",
        "        src_rules        [label=\"EMPLOYEE_ACTION_CHANGES_RULES\"];\n",
        "    }\n",
        "\n",
        "    // =====================================================\n",
        "    // 2. CHANGE DETECTION LAYER\n",
        "    // =====================================================\n",
        "    subgraph cluster_change {\n",
        "        label=\"CHANGE DETECTION LAYER\";\n",
        "        color=\"#AED6F1\";\n",
        "\n",
        "        ora_NOLSData [label=\"ora_NOLSData\\n(Build Change Code\\n+ Commentary\\n+ Flags)\"];\n",
        "    }\n",
        "\n",
        "    // =====================================================\n",
        "    // 3. HASH LOOKUP LAYER\n",
        "    // =====================================================\n",
        "    subgraph cluster_hash {\n",
        "        label=\"HASH LOOKUP LAYER\";\n",
        "        color=\"#ABEBC6\";\n",
        "\n",
        "        HSH_ACTION [label=\"HSH_BARCLAYS_EMPLOYEE_ACTION\"];\n",
        "        HSH_STG    [label=\"HSH_STG_F_BARCLAYS_MIDTERM_HIST\"];\n",
        "        HSH_RULES  [label=\"Rule_Lkps\"];\n",
        "        HSH_MIDTERM[label=\"HSH_MIDTERM_HIST\"];\n",
        "        HSH_REP    [label=\"EMP_ACT_CHG_REP_FLAG_HSH\"];\n",
        "    }\n",
        "\n",
        "    // =====================================================\n",
        "    // 4. CORE TRANSFORMATION LAYER\n",
        "    // =====================================================\n",
        "    subgraph cluster_core {\n",
        "        label=\"CORE TRANSFORMATION ENGINE\";\n",
        "        color=\"#F9E79F\";\n",
        "\n",
        "        tfmLookup [label=\"tfmLookupSubmittedCount\\n(Main Engine)\"];\n",
        "    }\n",
        "\n",
        "    // =====================================================\n",
        "    // 5. REPORTING ENGINE LAYER\n",
        "    // =====================================================\n",
        "    subgraph cluster_reporting {\n",
        "        label=\"REPORTING ENGINE\";\n",
        "        color=\"#F5B7B1\";\n",
        "\n",
        "        explode_stage [label=\"Ora_STG_EMPLOYEE_CHANGES_REPORTING\\n(Row Explosion / Unpivot)\"];\n",
        "        xfm_rules     [label=\"xfm_RuleLkps\"];\n",
        "        xfm_flag      [label=\"xfm_Reporting_flag\\n(Decision Engine)\"];\n",
        "    }\n",
        "\n",
        "    // =====================================================\n",
        "    // 6. TARGET LAYER\n",
        "    // =====================================================\n",
        "    subgraph cluster_target {\n",
        "        label=\"TARGET LOAD LAYER\";\n",
        "        color=\"#D7BDE2\";\n",
        "\n",
        "        tgt_midterm [label=\"STG_F_BARCLAYS_MIDTERM\"];\n",
        "        tgt_reporting [label=\"STG_EMPLOYEE_CHANGES_REPORTING\"];\n",
        "    }\n",
        "\n",
        "    // =====================================================\n",
        "    // FLOW CONNECTIONS\n",
        "    // =====================================================\n",
        "\n",
        "    // Source -> Change\n",
        "    src_midterm_hist -> ora_NOLSData;\n",
        "    src_prev_hist    -> ora_NOLSData;\n",
        "    src_grade_dim    -> ora_NOLSData;\n",
        "    src_upload       -> ora_NOLSData;\n",
        "\n",
        "    // Source -> Hash\n",
        "    src_action_dim -> HSH_ACTION;\n",
        "    src_rules      -> xfm_rules;\n",
        "\n",
        "    // Change -> Core\n",
        "    ora_NOLSData -> tfmLookup;\n",
        "\n",
        "    // Hash -> Core\n",
        "    HSH_ACTION -> tfmLookup;\n",
        "    HSH_STG    -> tfmLookup;\n",
        "\n",
        "    // Core -> Hash + Reporting\n",
        "    tfmLookup -> HSH_MIDTERM;\n",
        "    tfmLookup -> explode_stage;\n",
        "\n",
        "    // Reporting Flow\n",
        "    explode_stage -> xfm_flag;\n",
        "    xfm_rules -> HSH_RULES;\n",
        "    HSH_RULES -> xfm_flag;\n",
        "\n",
        "    // Reporting -> Hash\n",
        "    xfm_flag -> HSH_REP;\n",
        "\n",
        "    // Final Loads\n",
        "    tfmLookup -> tgt_midterm;\n",
        "    explode_stage -> tgt_reporting;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "graph = Source(dot_code)\n",
        "graph.render(\"LS_Sample_job1_Architecture\", format=\"pdf\")\n",
        "graph"
      ],
      "metadata": {
        "id": "4QiqBR4Bn2xf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c21851b9-8132-4ad3-acdd-46fa2249637f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: LS_Sample_job1_Architecture Pages: 1 -->\n<svg width=\"1114pt\" height=\"985pt\"\n viewBox=\"0.00 0.00 1114.00 985.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 981)\">\n<title>LS_Sample_job1_Architecture</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-981 1110,-981 1110,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_source</title>\n<polygon fill=\"none\" stroke=\"#d5dbdb\" points=\"8,-367 8,-969 240,-969 240,-367 8,-367\"/>\n<text text-anchor=\"middle\" x=\"124\" y=\"-953.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SOURCE LAYER (Oracle)</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_change</title>\n<polygon fill=\"none\" stroke=\"#aed6f1\" points=\"293,-723 293,-820 525,-820 525,-723 293,-723\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-804.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CHANGE DETECTION LAYER</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_hash</title>\n<polygon fill=\"none\" stroke=\"#abebc6\" points=\"293,-214 293,-715 525,-715 525,-214 293,-214\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-699.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">HASH LOOKUP LAYER</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_core</title>\n<polygon fill=\"none\" stroke=\"#f9e79f\" points=\"578,-466 578,-563 823,-563 823,-466 578,-466\"/>\n<text text-anchor=\"middle\" x=\"700.5\" y=\"-547.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CORE TRANSFORMATION ENGINE</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_reporting</title>\n<polygon fill=\"none\" stroke=\"#f5b7b1\" points=\"282,-8 282,-206 816,-206 816,-8 282,-8\"/>\n<text text-anchor=\"middle\" x=\"549\" y=\"-190.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">REPORTING ENGINE</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_target</title>\n<polygon fill=\"none\" stroke=\"#d7bde2\" points=\"865,-190 865,-388 1098,-388 1098,-190 865,-190\"/>\n<text text-anchor=\"middle\" x=\"981.5\" y=\"-372.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">TARGET LOAD LAYER</text>\n</g>\n<!-- src_midterm_hist -->\n<g id=\"node1\" class=\"node\">\n<title>src_midterm_hist</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M220,-938C220,-938 28,-938 28,-938 22,-938 16,-932 16,-926 16,-926 16,-892 16,-892 16,-886 22,-880 28,-880 28,-880 220,-880 220,-880 226,-880 232,-886 232,-892 232,-892 232,-926 232,-926 232,-932 226,-938 220,-938\"/>\n<text text-anchor=\"middle\" x=\"124\" y=\"-906.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">STG_F_BARCLAYS_MIDTERM_HIST</text>\n</g>\n<!-- ora_NOLSData -->\n<g id=\"node7\" class=\"node\">\n<title>ora_NOLSData</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M505,-789C505,-789 313,-789 313,-789 307,-789 301,-783 301,-777 301,-777 301,-743 301,-743 301,-737 307,-731 313,-731 313,-731 505,-731 505,-731 511,-731 517,-737 517,-743 517,-743 517,-777 517,-777 517,-783 511,-789 505,-789\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-774\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">ora_NOLSData</text>\n<text text-anchor=\"middle\" x=\"409\" y=\"-763\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(Build Change Code</text>\n<text text-anchor=\"middle\" x=\"409\" y=\"-752\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">+ Commentary</text>\n<text text-anchor=\"middle\" x=\"409\" y=\"-741\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">+ Flags)</text>\n</g>\n<!-- src_midterm_hist&#45;&gt;ora_NOLSData -->\n<g id=\"edge1\" class=\"edge\">\n<title>src_midterm_hist&#45;&gt;ora_NOLSData</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M232.15,-909C312.78,-909 409,-909 409,-909 409,-909 409,-797.08 409,-797.08\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"411.8,-797.08 409,-789.08 406.2,-797.08 411.8,-797.08\"/>\n</g>\n<!-- src_prev_hist -->\n<g id=\"node2\" class=\"node\">\n<title>src_prev_hist</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M220,-837C220,-837 28,-837 28,-837 22,-837 16,-831 16,-825 16,-825 16,-791 16,-791 16,-785 22,-779 28,-779 28,-779 220,-779 220,-779 226,-779 232,-785 232,-791 232,-791 232,-825 232,-825 232,-831 226,-837 220,-837\"/>\n<text text-anchor=\"middle\" x=\"124\" y=\"-805.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">F_BARCLAYS_MIDTERM_HIST</text>\n</g>\n<!-- src_prev_hist&#45;&gt;ora_NOLSData -->\n<g id=\"edge2\" class=\"edge\">\n<title>src_prev_hist&#45;&gt;ora_NOLSData</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M232.15,-784C232.15,-784 292.92,-784 292.92,-784\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"292.92,-786.8 300.92,-784 292.92,-781.2 292.92,-786.8\"/>\n</g>\n<!-- src_grade_dim -->\n<g id=\"node3\" class=\"node\">\n<title>src_grade_dim</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M220,-736C220,-736 28,-736 28,-736 22,-736 16,-730 16,-724 16,-724 16,-690 16,-690 16,-684 22,-678 28,-678 28,-678 220,-678 220,-678 226,-678 232,-684 232,-690 232,-690 232,-724 232,-724 232,-730 226,-736 220,-736\"/>\n<text text-anchor=\"middle\" x=\"124\" y=\"-704.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">CUST_DRIVER_GRADE_DIM</text>\n</g>\n<!-- src_grade_dim&#45;&gt;ora_NOLSData -->\n<g id=\"edge3\" class=\"edge\">\n<title>src_grade_dim&#45;&gt;ora_NOLSData</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M124,-736.17C124,-750.47 124,-764.67 124,-764.67 124,-764.67 292.85,-764.67 292.85,-764.67\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"292.85,-767.47 300.85,-764.67 292.85,-761.87 292.85,-767.47\"/>\n</g>\n<!-- src_upload -->\n<g id=\"node4\" class=\"node\">\n<title>src_upload</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M220,-635C220,-635 28,-635 28,-635 22,-635 16,-629 16,-623 16,-623 16,-589 16,-589 16,-583 22,-577 28,-577 28,-577 220,-577 220,-577 226,-577 232,-583 232,-589 232,-589 232,-623 232,-623 232,-629 226,-635 220,-635\"/>\n<text text-anchor=\"middle\" x=\"124\" y=\"-603.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">DRIVER_UPLOAD_EMAIL_DETAILS</text>\n</g>\n<!-- src_upload&#45;&gt;ora_NOLSData -->\n<g id=\"edge4\" class=\"edge\">\n<title>src_upload&#45;&gt;ora_NOLSData</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M232.28,-630.5C249.08,-630.5 261,-630.5 261,-630.5 261,-630.5 261,-750.33 261,-750.33 261,-750.33 292.66,-750.33 292.66,-750.33\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"292.66,-753.13 300.66,-750.33 292.66,-747.53 292.66,-753.13\"/>\n</g>\n<!-- src_action_dim -->\n<g id=\"node5\" class=\"node\">\n<title>src_action_dim</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M220,-534C220,-534 28,-534 28,-534 22,-534 16,-528 16,-522 16,-522 16,-488 16,-488 16,-482 22,-476 28,-476 28,-476 220,-476 220,-476 226,-476 232,-482 232,-488 232,-488 232,-522 232,-522 232,-528 226,-534 220,-534\"/>\n<text text-anchor=\"middle\" x=\"124\" y=\"-502.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">D_BARCLAYS_EMPLOYEE_ACTION</text>\n</g>\n<!-- HSH_ACTION -->\n<g id=\"node8\" class=\"node\">\n<title>HSH_ACTION</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M505,-583C505,-583 313,-583 313,-583 307,-583 301,-577 301,-571 301,-571 301,-537 301,-537 301,-531 307,-525 313,-525 313,-525 505,-525 505,-525 511,-525 517,-531 517,-537 517,-537 517,-571 517,-571 517,-577 511,-583 505,-583\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-551.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">HSH_BARCLAYS_EMPLOYEE_ACTION</text>\n</g>\n<!-- src_action_dim&#45;&gt;HSH_ACTION -->\n<g id=\"edge5\" class=\"edge\">\n<title>src_action_dim&#45;&gt;HSH_ACTION</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M232.15,-529.5C232.15,-529.5 292.92,-529.5 292.92,-529.5\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"292.92,-532.3 300.92,-529.5 292.92,-526.7 292.92,-532.3\"/>\n</g>\n<!-- src_rules -->\n<g id=\"node6\" class=\"node\">\n<title>src_rules</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M220,-433C220,-433 28,-433 28,-433 22,-433 16,-427 16,-421 16,-421 16,-387 16,-387 16,-381 22,-375 28,-375 28,-375 220,-375 220,-375 226,-375 232,-381 232,-387 232,-387 232,-421 232,-421 232,-427 226,-433 220,-433\"/>\n<text text-anchor=\"middle\" x=\"124\" y=\"-401.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">EMPLOYEE_ACTION_CHANGES_RULES</text>\n</g>\n<!-- xfm_rules -->\n<g id=\"node15\" class=\"node\">\n<title>xfm_rules</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M505,-74C505,-74 313,-74 313,-74 307,-74 301,-68 301,-62 301,-62 301,-28 301,-28 301,-22 307,-16 313,-16 313,-16 505,-16 505,-16 511,-16 517,-22 517,-28 517,-28 517,-62 517,-62 517,-68 511,-74 505,-74\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-42.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">xfm_RuleLkps</text>\n</g>\n<!-- src_rules&#45;&gt;xfm_rules -->\n<g id=\"edge6\" class=\"edge\">\n<title>src_rules&#45;&gt;xfm_rules</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M124,-374.93C124,-289.46 124,-45 124,-45 124,-45 292.85,-45 292.85,-45\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"292.85,-47.8 300.85,-45 292.85,-42.2 292.85,-47.8\"/>\n</g>\n<!-- tfmLookup -->\n<g id=\"node13\" class=\"node\">\n<title>tfmLookup</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M796,-532C796,-532 604,-532 604,-532 598,-532 592,-526 592,-520 592,-520 592,-486 592,-486 592,-480 598,-474 604,-474 604,-474 796,-474 796,-474 802,-474 808,-480 808,-486 808,-486 808,-520 808,-520 808,-526 802,-532 796,-532\"/>\n<text text-anchor=\"middle\" x=\"700\" y=\"-506\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">tfmLookupSubmittedCount</text>\n<text text-anchor=\"middle\" x=\"700\" y=\"-495\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(Main Engine)</text>\n</g>\n<!-- ora_NOLSData&#45;&gt;tfmLookup -->\n<g id=\"edge7\" class=\"edge\">\n<title>ora_NOLSData&#45;&gt;tfmLookup</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M517.43,-760C612.62,-760 736,-760 736,-760 736,-760 736,-540.48 736,-540.48\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"738.8,-540.48 736,-532.48 733.2,-540.48 738.8,-540.48\"/>\n</g>\n<!-- HSH_ACTION&#45;&gt;tfmLookup -->\n<g id=\"edge8\" class=\"edge\">\n<title>HSH_ACTION&#45;&gt;tfmLookup</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M517.36,-528.5C517.36,-528.5 583.55,-528.5 583.55,-528.5\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"583.55,-531.3 591.55,-528.5 583.55,-525.7 583.55,-531.3\"/>\n</g>\n<!-- HSH_STG -->\n<g id=\"node9\" class=\"node\">\n<title>HSH_STG</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M505,-482C505,-482 313,-482 313,-482 307,-482 301,-476 301,-470 301,-470 301,-436 301,-436 301,-430 307,-424 313,-424 313,-424 505,-424 505,-424 511,-424 517,-430 517,-436 517,-436 517,-470 517,-470 517,-476 511,-482 505,-482\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-450.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">HSH_STG_F_BARCLAYS_MIDTERM_HIST</text>\n</g>\n<!-- HSH_STG&#45;&gt;tfmLookup -->\n<g id=\"edge9\" class=\"edge\">\n<title>HSH_STG&#45;&gt;tfmLookup</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M517.36,-479.33C517.36,-479.33 583.55,-479.33 583.55,-479.33\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"583.55,-482.13 591.55,-479.33 583.55,-476.53 583.55,-482.13\"/>\n</g>\n<!-- HSH_RULES -->\n<g id=\"node10\" class=\"node\">\n<title>HSH_RULES</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M505,-381C505,-381 313,-381 313,-381 307,-381 301,-375 301,-369 301,-369 301,-335 301,-335 301,-329 307,-323 313,-323 313,-323 505,-323 505,-323 511,-323 517,-329 517,-335 517,-335 517,-369 517,-369 517,-375 511,-381 505,-381\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-349.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Rule_Lkps</text>\n</g>\n<!-- xfm_flag -->\n<g id=\"node16\" class=\"node\">\n<title>xfm_flag</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M796,-175C796,-175 604,-175 604,-175 598,-175 592,-169 592,-163 592,-163 592,-129 592,-129 592,-123 598,-117 604,-117 604,-117 796,-117 796,-117 802,-117 808,-123 808,-129 808,-129 808,-163 808,-163 808,-169 802,-175 796,-175\"/>\n<text text-anchor=\"middle\" x=\"700\" y=\"-149\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">xfm_Reporting_flag</text>\n<text text-anchor=\"middle\" x=\"700\" y=\"-138\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(Decision Engine)</text>\n</g>\n<!-- HSH_RULES&#45;&gt;xfm_flag -->\n<g id=\"edge14\" class=\"edge\">\n<title>HSH_RULES&#45;&gt;xfm_flag</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M517.36,-340C600.09,-340 700,-340 700,-340 700,-340 700,-183.04 700,-183.04\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"702.8,-183.04 700,-175.04 697.2,-183.04 702.8,-183.04\"/>\n</g>\n<!-- HSH_MIDTERM -->\n<g id=\"node11\" class=\"node\">\n<title>HSH_MIDTERM</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M505,-684C505,-684 313,-684 313,-684 307,-684 301,-678 301,-672 301,-672 301,-638 301,-638 301,-632 307,-626 313,-626 313,-626 505,-626 505,-626 511,-626 517,-632 517,-638 517,-638 517,-672 517,-672 517,-678 511,-684 505,-684\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-652.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">HSH_MIDTERM_HIST</text>\n</g>\n<!-- HSH_REP -->\n<g id=\"node12\" class=\"node\">\n<title>HSH_REP</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M505,-280C505,-280 313,-280 313,-280 307,-280 301,-274 301,-268 301,-268 301,-234 301,-234 301,-228 307,-222 313,-222 313,-222 505,-222 505,-222 511,-222 517,-228 517,-234 517,-234 517,-268 517,-268 517,-274 511,-280 505,-280\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-248.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">EMP_ACT_CHG_REP_FLAG_HSH</text>\n</g>\n<!-- tfmLookup&#45;&gt;HSH_MIDTERM -->\n<g id=\"edge10\" class=\"edge\">\n<title>tfmLookup&#45;&gt;HSH_MIDTERM</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M664,-532.31C664,-576.48 664,-655 664,-655 664,-655 525.14,-655 525.14,-655\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"525.14,-652.2 517.14,-655 525.14,-657.8 525.14,-652.2\"/>\n</g>\n<!-- explode_stage -->\n<g id=\"node14\" class=\"node\">\n<title>explode_stage</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M516,-175C516,-175 302,-175 302,-175 296,-175 290,-169 290,-163 290,-163 290,-129 290,-129 290,-123 296,-117 302,-117 302,-117 516,-117 516,-117 522,-117 528,-123 528,-129 528,-129 528,-163 528,-163 528,-169 522,-175 516,-175\"/>\n<text text-anchor=\"middle\" x=\"409\" y=\"-149\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">Ora_STG_EMPLOYEE_CHANGES_REPORTING</text>\n<text text-anchor=\"middle\" x=\"409\" y=\"-138\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">(Row Explosion / Unpivot)</text>\n</g>\n<!-- tfmLookup&#45;&gt;explode_stage -->\n<g id=\"edge11\" class=\"edge\">\n<title>tfmLookup&#45;&gt;explode_stage</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M591.75,-476.67C554.05,-476.67 521,-476.67 521,-476.67 521,-476.67 521,-183.05 521,-183.05\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"523.8,-183.05 521,-175.05 518.2,-183.05 523.8,-183.05\"/>\n</g>\n<!-- tgt_midterm -->\n<g id=\"node17\" class=\"node\">\n<title>tgt_midterm</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M1077.5,-357C1077.5,-357 885.5,-357 885.5,-357 879.5,-357 873.5,-351 873.5,-345 873.5,-345 873.5,-311 873.5,-311 873.5,-305 879.5,-299 885.5,-299 885.5,-299 1077.5,-299 1077.5,-299 1083.5,-299 1089.5,-305 1089.5,-311 1089.5,-311 1089.5,-345 1089.5,-345 1089.5,-351 1083.5,-357 1077.5,-357\"/>\n<text text-anchor=\"middle\" x=\"981.5\" y=\"-325.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">STG_F_BARCLAYS_MIDTERM</text>\n</g>\n<!-- tfmLookup&#45;&gt;tgt_midterm -->\n<g id=\"edge16\" class=\"edge\">\n<title>tfmLookup&#45;&gt;tgt_midterm</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M754,-473.94C754,-429.18 754,-348.5 754,-348.5 754,-348.5 865.41,-348.5 865.41,-348.5\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"865.41,-351.3 873.41,-348.5 865.41,-345.7 865.41,-351.3\"/>\n</g>\n<!-- explode_stage&#45;&gt;xfm_flag -->\n<g id=\"edge12\" class=\"edge\">\n<title>explode_stage&#45;&gt;xfm_flag</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M528.2,-146C528.2,-146 583.74,-146 583.74,-146\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"583.74,-148.8 591.74,-146 583.74,-143.2 583.74,-148.8\"/>\n</g>\n<!-- tgt_reporting -->\n<g id=\"node18\" class=\"node\">\n<title>tgt_reporting</title>\n<path fill=\"#f4f6f7\" stroke=\"#2c3e50\" d=\"M1078,-256C1078,-256 885,-256 885,-256 879,-256 873,-250 873,-244 873,-244 873,-210 873,-210 873,-204 879,-198 885,-198 885,-198 1078,-198 1078,-198 1084,-198 1090,-204 1090,-210 1090,-210 1090,-244 1090,-244 1090,-250 1084,-256 1078,-256\"/>\n<text text-anchor=\"middle\" x=\"981.5\" y=\"-224.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">STG_EMPLOYEE_CHANGES_REPORTING</text>\n</g>\n<!-- explode_stage&#45;&gt;tgt_reporting -->\n<g id=\"edge17\" class=\"edge\">\n<title>explode_stage&#45;&gt;tgt_reporting</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M525,-175C525,-191.94 525,-210 525,-210 525,-210 864.74,-210 864.74,-210\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"864.74,-212.8 872.74,-210 864.74,-207.2 864.74,-212.8\"/>\n</g>\n<!-- xfm_rules&#45;&gt;HSH_RULES -->\n<g id=\"edge13\" class=\"edge\">\n<title>xfm_rules&#45;&gt;HSH_RULES</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M517.13,-45C541.34,-45 560,-45 560,-45 560,-45 560,-331.5 560,-331.5 560,-331.5 525.13,-331.5 525.13,-331.5\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"525.13,-328.7 517.13,-331.5 525.13,-334.3 525.13,-328.7\"/>\n</g>\n<!-- xfm_flag&#45;&gt;HSH_REP -->\n<g id=\"edge15\" class=\"edge\">\n<title>xfm_flag&#45;&gt;HSH_REP</title>\n<path fill=\"none\" stroke=\"#34495e\" d=\"M646,-175.17C646,-202.44 646,-239 646,-239 646,-239 525.1,-239 525.1,-239\"/>\n<polygon fill=\"#34495e\" stroke=\"#34495e\" points=\"525.1,-236.2 517.1,-239 525.1,-241.8 525.1,-236.2\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7e7201eb2c30>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from graphviz import Digraph\n",
        "\n",
        "def parse_pseudocode(text):\n",
        "    stages = {}\n",
        "    dataset_producers = {}\n",
        "\n",
        "    stage_pattern = r\"--- \\[(.*?) : (.*?)\\]\"\n",
        "    input_pattern = r\"Input:\\s*←\\s*(dataset_\\d+)\"\n",
        "    output_pattern = r\"Output:\\s*→\\s*(dataset_\\d+)\"\n",
        "\n",
        "    current_stage = None\n",
        "\n",
        "    for line in text.splitlines():\n",
        "\n",
        "        stage_match = re.search(stage_pattern, line)\n",
        "        if stage_match:\n",
        "            stage_type = stage_match.group(1).strip()\n",
        "            stage_name = stage_match.group(2).strip()\n",
        "            current_stage = stage_name\n",
        "\n",
        "            stages[current_stage] = {\n",
        "                \"type\": stage_type,\n",
        "                \"inputs\": [],\n",
        "                \"outputs\": []\n",
        "            }\n",
        "            continue\n",
        "\n",
        "        if current_stage:\n",
        "            input_match = re.search(input_pattern, line)\n",
        "            if input_match:\n",
        "                stages[current_stage][\"inputs\"].append(input_match.group(1))\n",
        "\n",
        "            output_match = re.search(output_pattern, line)\n",
        "            if output_match:\n",
        "                dataset = output_match.group(1)\n",
        "                stages[current_stage][\"outputs\"].append(dataset)\n",
        "                dataset_producers[dataset] = current_stage\n",
        "\n",
        "    return stages, dataset_producers\n",
        "\n",
        "\n",
        "def build_graph(stages, dataset_producers):\n",
        "    dot = Digraph(comment=\"Auto Generated ETL Architecture\")\n",
        "    dot.attr(rankdir=\"LR\")\n",
        "\n",
        "    # Create stage nodes\n",
        "    for stage, info in stages.items():\n",
        "        dot.node(stage, f\"{stage}\\n({info['type']})\")\n",
        "\n",
        "    # Create connections\n",
        "    for stage, info in stages.items():\n",
        "        for dataset in info[\"inputs\"]:\n",
        "            if dataset in dataset_producers:\n",
        "                source_stage = dataset_producers[dataset]\n",
        "                dot.edge(source_stage, stage)\n",
        "\n",
        "    return dot\n",
        "\n",
        "with open(\"LS_Sample_job1 1 2_detailed_pseudocode.txt\", \"r\") as f:\n",
        "    pseudo_text = f.read()\n",
        "\n",
        "stages, producers = parse_pseudocode(pseudo_text)\n",
        "graph = build_graph(stages, producers)\n",
        "\n",
        "graph.render(\"auto_etl_architecture\", format=\"pdf\")\n"
      ],
      "metadata": {
        "id": "6ps0QFYen2zu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "191cb2c5-b54f-400f-d5ee-29d9a17f97fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'auto_etl_architecture.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from graphviz import Digraph\n",
        "\n",
        "# -----------------------------\n",
        "# 1️⃣ Layer Classification\n",
        "# -----------------------------\n",
        "def classify_layer(stage_type):\n",
        "    stage_type = stage_type.upper()\n",
        "\n",
        "    if \"ORACLE\" in stage_type or \"CUSTOM\" in stage_type:\n",
        "        return \"SOURCE_TARGET\"\n",
        "\n",
        "    if \"HASHED\" in stage_type:\n",
        "        return \"HASH\"\n",
        "\n",
        "    if \"TRANSFORMER\" in stage_type:\n",
        "        return \"TRANSFORM\"\n",
        "\n",
        "    return \"OTHER\"\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2️⃣ Parse Pseudocode\n",
        "# -----------------------------\n",
        "def parse_pseudocode(text):\n",
        "    stages = {}\n",
        "    dataset_producers = {}\n",
        "\n",
        "    stage_pattern = r\"--- \\[(.*?) : (.*?)\\]\"\n",
        "    input_pattern = r\"Input:\\s*←\\s*(dataset_\\d+)\"\n",
        "    output_pattern = r\"Output:\\s*→\\s*(dataset_\\d+)\"\n",
        "\n",
        "    current_stage = None\n",
        "\n",
        "    for line in text.splitlines():\n",
        "\n",
        "        stage_match = re.search(stage_pattern, line)\n",
        "        if stage_match:\n",
        "            stage_type = stage_match.group(1).strip()\n",
        "            stage_name = stage_match.group(2).strip()\n",
        "\n",
        "            current_stage = stage_name\n",
        "            stages[current_stage] = {\n",
        "                \"type\": stage_type,\n",
        "                \"inputs\": [],\n",
        "                \"outputs\": [],\n",
        "                \"layer\": classify_layer(stage_type)\n",
        "            }\n",
        "            continue\n",
        "\n",
        "        if current_stage:\n",
        "            input_match = re.search(input_pattern, line)\n",
        "            if input_match:\n",
        "                stages[current_stage][\"inputs\"].append(input_match.group(1))\n",
        "\n",
        "            output_match = re.search(output_pattern, line)\n",
        "            if output_match:\n",
        "                dataset = output_match.group(1)\n",
        "                stages[current_stage][\"outputs\"].append(dataset)\n",
        "                dataset_producers[dataset] = current_stage\n",
        "\n",
        "    return stages, dataset_producers\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3️⃣ Build Enterprise Graph\n",
        "# -----------------------------\n",
        "def build_enterprise_graph(stages, dataset_producers):\n",
        "    dot = Digraph(\"ETL_Architecture\")\n",
        "    dot.attr(rankdir=\"LR\", splines=\"ortho\")\n",
        "    dot.attr(\"node\", shape=\"box\", style=\"rounded,filled\",\n",
        "             width=\"3\", height=\"0.8\", fontname=\"Helvetica\")\n",
        "\n",
        "    # Create clusters\n",
        "    clusters = {\n",
        "        \"SOURCE_TARGET\": {\"color\": \"#AED6F1\", \"label\": \"SOURCE / TARGET\"},\n",
        "        \"TRANSFORM\": {\"color\": \"#F9E79F\", \"label\": \"TRANSFORMATION\"},\n",
        "        \"HASH\": {\"color\": \"#ABEBC6\", \"label\": \"HASH LOOKUP\"},\n",
        "        \"OTHER\": {\"color\": \"#D5DBDB\", \"label\": \"OTHER\"}\n",
        "    }\n",
        "\n",
        "    subgraphs = {}\n",
        "\n",
        "    for layer, props in clusters.items():\n",
        "        sub = Digraph(name=f\"cluster_{layer}\")\n",
        "        sub.attr(label=props[\"label\"], color=props[\"color\"])\n",
        "        subgraphs[layer] = sub\n",
        "\n",
        "    # Add nodes to clusters\n",
        "    for stage, info in stages.items():\n",
        "        layer = info[\"layer\"]\n",
        "        label = f\"{stage}\\n({info['type']})\"\n",
        "\n",
        "        subgraphs[layer].node(stage, label)\n",
        "\n",
        "    # Add clusters to main graph\n",
        "    for sub in subgraphs.values():\n",
        "        dot.subgraph(sub)\n",
        "\n",
        "    # Add edges\n",
        "    for stage, info in stages.items():\n",
        "        for dataset in info[\"inputs\"]:\n",
        "            if dataset in dataset_producers:\n",
        "                source_stage = dataset_producers[dataset]\n",
        "                dot.edge(source_stage, stage)\n",
        "\n",
        "    return dot\n",
        "with open(\"LS_Sample_job1 1 2_detailed_pseudocode.txt\", \"r\") as f:\n",
        "    pseudo_text = f.read()\n",
        "\n",
        "stages, producers = parse_pseudocode(pseudo_text)\n",
        "graph = build_enterprise_graph(stages, producers)\n",
        "\n",
        "graph.render(\"enterprise_auto_etl_architecture\", format=\"pdf\")\n"
      ],
      "metadata": {
        "id": "PmMBgK2vRrGf",
        "outputId": "f0bd4696-4416-40f3-9fb0-67c5327dd8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'enterprise_auto_etl_architecture.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from graphviz import Digraph\n",
        "\n",
        "def classify_layer(stage_type):\n",
        "    stage_type = stage_type.upper()\n",
        "\n",
        "    if \"ORACLE\" in stage_type or \"CUSTOM\" in stage_type:\n",
        "        return \"SOURCE_TARGET\"\n",
        "\n",
        "    if \"HASHED\" in stage_type:\n",
        "        return \"HASH\"\n",
        "\n",
        "    if \"TRANSFORMER\" in stage_type:\n",
        "        return \"TRANSFORM\"\n",
        "\n",
        "    return \"OTHER\"\n",
        "\n",
        "\n",
        "def parse_pseudocode(text):\n",
        "    stages = {}\n",
        "    dataset_producers = {}\n",
        "\n",
        "    stage_pattern = r\"--- \\[(.*?) : (.*?)\\]\"\n",
        "    input_pattern = r\"Input:\\s*←\\s*(dataset_\\d+)\"\n",
        "    output_pattern = r\"Output:\\s*→\\s*(dataset_\\d+)\"\n",
        "\n",
        "    current_stage = None\n",
        "\n",
        "    for line in text.splitlines():\n",
        "\n",
        "        stage_match = re.search(stage_pattern, line)\n",
        "        if stage_match:\n",
        "            stage_type = stage_match.group(1).strip()\n",
        "            stage_name = stage_match.group(2).strip()\n",
        "\n",
        "            current_stage = stage_name\n",
        "            stages[current_stage] = {\n",
        "                \"type\": stage_type,\n",
        "                \"inputs\": [],\n",
        "                \"outputs\": [],\n",
        "                \"layer\": classify_layer(stage_type)\n",
        "            }\n",
        "            continue\n",
        "\n",
        "        if current_stage:\n",
        "            input_match = re.search(input_pattern, line)\n",
        "            if input_match:\n",
        "                stages[current_stage][\"inputs\"].append(input_match.group(1))\n",
        "\n",
        "            output_match = re.search(output_pattern, line)\n",
        "            if output_match:\n",
        "                dataset = output_match.group(1)\n",
        "                stages[current_stage][\"outputs\"].append(dataset)\n",
        "                dataset_producers[dataset] = current_stage\n",
        "\n",
        "    return stages, dataset_producers\n",
        "\n",
        "\n",
        "def build_clean_architecture(stages, dataset_producers):\n",
        "    dot = Digraph(\"ETL_Architecture\", engine=\"dot\")\n",
        "    dot.attr(rankdir=\"LR\", splines=\"spline\", nodesep=\"0.8\", ranksep=\"1\")\n",
        "\n",
        "    dot.attr(\"node\",\n",
        "             shape=\"box\",\n",
        "             style=\"rounded,filled\",\n",
        "             fillcolor=\"#F4F6F7\",\n",
        "             width=\"3\",\n",
        "             height=\"0.8\")\n",
        "\n",
        "    # Create nodes\n",
        "    for stage, info in stages.items():\n",
        "        label = f\"{stage}\\n({info['type']})\"\n",
        "        dot.node(stage, label)\n",
        "\n",
        "    # Create edges\n",
        "    for stage, info in stages.items():\n",
        "        for dataset in info[\"inputs\"]:\n",
        "            if dataset in dataset_producers:\n",
        "                source_stage = dataset_producers[dataset]\n",
        "\n",
        "                # If lookup/hash → do not affect layout\n",
        "                if \"HASH\" in stages[source_stage][\"layer\"]:\n",
        "                    dot.edge(source_stage, stage,\n",
        "                             constraint=\"false\",\n",
        "                             color=\"gray\")\n",
        "\n",
        "                else:\n",
        "                    dot.edge(source_stage, stage)\n",
        "\n",
        "    return dot\n",
        "\n",
        "with open(\"Sample_Job1 1 2_detailed_pseudocode.txt\", \"r\") as f:\n",
        "    pseudo_text = f.read()\n",
        "\n",
        "stages, producers = parse_pseudocode(pseudo_text)\n",
        "graph = build_clean_architecture(stages, producers)\n",
        "\n",
        "# graph.render(\"enterprise_auto_etl_architecture1\", format=\"pdf\")\n"
      ],
      "metadata": {
        "id": "b-Oo6XAGSSMJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, deque\n",
        "\n",
        "def compute_depths(stages, dataset_producers):\n",
        "    graph = defaultdict(list)\n",
        "    indegree = defaultdict(int)\n",
        "\n",
        "    # Build graph\n",
        "    for stage, info in stages.items():\n",
        "        for dataset in info[\"inputs\"]:\n",
        "            if dataset in dataset_producers:\n",
        "                parent = dataset_producers[dataset]\n",
        "                graph[parent].append(stage)\n",
        "                indegree[stage] += 1\n",
        "\n",
        "    # Find roots\n",
        "    queue = deque()\n",
        "    depth = {}\n",
        "\n",
        "    for stage in stages:\n",
        "        if indegree[stage] == 0:\n",
        "            queue.append(stage)\n",
        "            depth[stage] = 0\n",
        "\n",
        "    # BFS for depth\n",
        "    while queue:\n",
        "        node = queue.popleft()\n",
        "        for neighbor in graph[node]:\n",
        "            indegree[neighbor] -= 1\n",
        "            if indegree[neighbor] == 0:\n",
        "                depth[neighbor] = depth[node] + 1\n",
        "                queue.append(neighbor)\n",
        "\n",
        "    return depth\n",
        "\n",
        "def build_depth_based_graph(stages, dataset_producers):\n",
        "    dot = Digraph(\"ETL_Architecture\", engine=\"dot\")\n",
        "    dot.attr(rankdir=\"LR\", splines=\"spline\", nodesep=\"0.8\", ranksep=\"1\")\n",
        "\n",
        "    dot.attr(\"node\",\n",
        "             shape=\"box\",\n",
        "             style=\"rounded,filled\",\n",
        "             fillcolor=\"#F4F6F7\",\n",
        "             width=\"3\",\n",
        "             height=\"0.8\")\n",
        "\n",
        "    depths = compute_depths(stages, dataset_producers)\n",
        "\n",
        "    # Group by depth\n",
        "    levels = defaultdict(list)\n",
        "    for stage, d in depths.items():\n",
        "        levels[d].append(stage)\n",
        "\n",
        "    # Create ranked layers\n",
        "    for d in sorted(levels):\n",
        "        with dot.subgraph() as s:\n",
        "            s.attr(rank=\"same\")\n",
        "            for stage in levels[d]:\n",
        "                label = f\"{stage}\\n({stages[stage]['type']})\"\n",
        "                s.node(stage, label)\n",
        "\n",
        "    # Add edges\n",
        "    for stage, info in stages.items():\n",
        "        for dataset in info[\"inputs\"]:\n",
        "            if dataset in dataset_producers:\n",
        "                parent = dataset_producers[dataset]\n",
        "\n",
        "                # Lookup edges don't disturb layout\n",
        "                if \"HASH\" in stages[parent][\"layer\"]:\n",
        "                    dot.edge(parent, stage,\n",
        "                             constraint=\"false\",\n",
        "                             color=\"gray\")\n",
        "\n",
        "                else:\n",
        "                    dot.edge(parent, stage)\n",
        "\n",
        "    return dot\n",
        "\n",
        "stages, producers = parse_pseudocode(pseudo_text)\n",
        "graph = build_depth_based_graph(stages, producers)\n",
        "\n",
        "graph.render(\"enterprise_auto_etl_architecture3\", format=\"pdf\")\n"
      ],
      "metadata": {
        "id": "5qs_o8W3Toyn",
        "outputId": "d085bbee-107d-42e4-c4bf-2018909b3e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'enterprise_auto_etl_architecture3.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from graphviz import Digraph\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 1️⃣  CLASSIFY STAGE TYPES\n",
        "# =====================================================\n",
        "\n",
        "def classify_layer(stage_type):\n",
        "    stage_type = stage_type.upper()\n",
        "\n",
        "    if \"TRANSFORMER\" in stage_type:\n",
        "        return \"TRANSFORM\"\n",
        "\n",
        "    if \"HASHED\" in stage_type:\n",
        "        return \"HASH\"\n",
        "\n",
        "    if \"SEQ\" in stage_type:\n",
        "        return \"FILE\"\n",
        "\n",
        "    if \"ORACLE\" in stage_type or \"CUSTOM\" in stage_type:\n",
        "        return \"DB\"\n",
        "\n",
        "    return \"OTHER\"\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 2️⃣  PARSE PSEUDOCODE\n",
        "# =====================================================\n",
        "\n",
        "def parse_pseudocode(text):\n",
        "    stages = {}\n",
        "    dataset_producers = {}\n",
        "\n",
        "    stage_pattern = r\"--- \\[(.*?) : (.*?)\\]\"\n",
        "    input_pattern = r\"Input:\\s*←\\s*(dataset_\\d+)\"\n",
        "    output_pattern = r\"Output:\\s*→\\s*(dataset_\\d+)\"\n",
        "\n",
        "    current_stage = None\n",
        "\n",
        "    for line in text.splitlines():\n",
        "\n",
        "        stage_match = re.search(stage_pattern, line)\n",
        "        if stage_match:\n",
        "            stage_type = stage_match.group(1).strip()\n",
        "            stage_name = stage_match.group(2).strip()\n",
        "\n",
        "            current_stage = stage_name\n",
        "            stages[current_stage] = {\n",
        "                \"type\": stage_type,\n",
        "                \"inputs\": [],\n",
        "                \"outputs\": [],\n",
        "                \"layer\": classify_layer(stage_type)\n",
        "            }\n",
        "            continue\n",
        "\n",
        "        if current_stage:\n",
        "            input_match = re.search(input_pattern, line)\n",
        "            if input_match:\n",
        "                stages[current_stage][\"inputs\"].append(input_match.group(1))\n",
        "\n",
        "            output_match = re.search(output_pattern, line)\n",
        "            if output_match:\n",
        "                dataset = output_match.group(1)\n",
        "                stages[current_stage][\"outputs\"].append(dataset)\n",
        "                dataset_producers[dataset] = current_stage\n",
        "\n",
        "    return stages, dataset_producers\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 3️⃣  COMPUTE EXECUTION DEPTH (TRUE PIPELINE ORDER)\n",
        "# =====================================================\n",
        "\n",
        "def compute_depths(stages, dataset_producers):\n",
        "\n",
        "    graph = defaultdict(list)\n",
        "    indegree = defaultdict(int)\n",
        "\n",
        "    for stage, info in stages.items():\n",
        "        for dataset in info[\"inputs\"]:\n",
        "            if dataset in dataset_producers:\n",
        "                parent = dataset_producers[dataset]\n",
        "                graph[parent].append(stage)\n",
        "                indegree[stage] += 1\n",
        "\n",
        "    depth = {}\n",
        "    queue = deque()\n",
        "\n",
        "    for stage in stages:\n",
        "        if indegree[stage] == 0:\n",
        "            queue.append(stage)\n",
        "            depth[stage] = 0\n",
        "\n",
        "    while queue:\n",
        "        node = queue.popleft()\n",
        "        for neighbor in graph[node]:\n",
        "            indegree[neighbor] -= 1\n",
        "            if indegree[neighbor] == 0:\n",
        "                depth[neighbor] = depth[node] + 1\n",
        "                queue.append(neighbor)\n",
        "\n",
        "    return depth\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 4️⃣  BUILD STRICT LEFT→RIGHT ARCHITECTURE\n",
        "# =====================================================\n",
        "\n",
        "def build_strict_left_to_right(stages, dataset_producers):\n",
        "\n",
        "    dot = Digraph(\"ETL_Flow\", engine=\"dot\")\n",
        "\n",
        "    dot.attr(rankdir=\"LR\")\n",
        "    dot.attr(splines=\"spline\")\n",
        "    dot.attr(nodesep=\"0.8\")\n",
        "    dot.attr(ranksep=\"1.2\")\n",
        "\n",
        "    dot.attr(\"node\",\n",
        "             shape=\"box\",\n",
        "             style=\"rounded,filled\",\n",
        "             fillcolor=\"#F4F6F7\",\n",
        "             width=\"3\",\n",
        "             height=\"0.8\")\n",
        "\n",
        "    depths = compute_depths(stages, dataset_producers)\n",
        "\n",
        "    # Detect final target nodes (no outgoing edges)\n",
        "    outgoing = defaultdict(int)\n",
        "    for stage, info in stages.items():\n",
        "        for dataset in info[\"inputs\"]:\n",
        "            if dataset in dataset_producers:\n",
        "                parent = dataset_producers[dataset]\n",
        "                outgoing[parent] += 1\n",
        "\n",
        "    targets = [s for s in stages if outgoing[s] == 0]\n",
        "\n",
        "    # Move final DB targets one level deeper\n",
        "    max_depth = max(depths.values())\n",
        "    for t in targets:\n",
        "        if stages[t][\"layer\"] == \"DB\":\n",
        "            depths[t] = max_depth + 1\n",
        "\n",
        "    # Group nodes by depth\n",
        "    levels = defaultdict(list)\n",
        "    for stage, d in depths.items():\n",
        "        levels[d].append(stage)\n",
        "\n",
        "    # Create ranked layers\n",
        "    for d in sorted(levels):\n",
        "        with dot.subgraph() as s:\n",
        "            s.attr(rank=\"same\")\n",
        "            for stage in levels[d]:\n",
        "                label = f\"{stage}\\n({stages[stage]['type']})\"\n",
        "\n",
        "                color = \"#F4F6F7\"\n",
        "                if stages[stage][\"layer\"] == \"DB\":\n",
        "                    color = \"#AED6F1\"\n",
        "                elif stages[stage][\"layer\"] == \"TRANSFORM\":\n",
        "                    color = \"#F9E79F\"\n",
        "                elif stages[stage][\"layer\"] == \"HASH\":\n",
        "                    color = \"#ABEBC6\"\n",
        "                elif stages[stage][\"layer\"] == \"FILE\":\n",
        "                    color = \"#F5B7B1\"\n",
        "\n",
        "                s.node(stage, label, fillcolor=color)\n",
        "\n",
        "    # Add edges\n",
        "    for stage, info in stages.items():\n",
        "        for dataset in info[\"inputs\"]:\n",
        "            if dataset in dataset_producers:\n",
        "                parent = dataset_producers[dataset]\n",
        "\n",
        "                # HASH lookups should not distort layout\n",
        "                if stages[parent][\"layer\"] == \"HASH\":\n",
        "                    dot.edge(parent, stage,\n",
        "                             constraint=\"false\",\n",
        "                             color=\"gray\")\n",
        "\n",
        "                else:\n",
        "                    dot.edge(parent, stage)\n",
        "\n",
        "    return dot\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 5️⃣  RUN\n",
        "# =====================================================\n",
        "\n",
        "with open(\"Samle_Job2 1 2_detailed_pseudocode.txt\", \"r\") as f:\n",
        "    pseudo_text = f.read()\n",
        "\n",
        "stages, producers = parse_pseudocode(pseudo_text)\n",
        "\n",
        "graph = build_strict_left_to_right(stages, producers)\n",
        "\n",
        "graph.render(\"final_clean_etl_flow2 1 2\", format=\"pdf\")\n"
      ],
      "metadata": {
        "id": "k9a4Ann_pyzI",
        "outputId": "f61d6ac5-6308-4e56-c78e-731f20fd16e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'final_clean_etl_flow2 1 2.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6B9Mq2k0py2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}